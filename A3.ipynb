{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjh1009/UTS_ML2019_ID12794881/blob/master/A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf-j0mykGSI7",
        "colab_type": "text"
      },
      "source": [
        "1. Introduction: \n",
        "In this age of information development, social media is becoming more and more common in people's lives, and a variety of social media are being designed. Obviously, social media has changed the way people interact. The topic in this report is to use the information or messages from social media to predict how to make the user can be converted to change their support. This report is going to explain the problem, list three challenges for the problem, simple describe a system designed to solve the problem. Finally, discuss the ethical issues and social consequence of this study.\n",
        "\n",
        "2. Problem: \n",
        "As a data analyst for a polling organisation, company ask me to design a system to solve a problem, which might appearance while using the information or messages from social media to predict how to make the user can be converted to change their support. There are three challenges shows at the next part, which is reliability problem, classify problem and how to let users receive this information.\n",
        "\n",
        "3. Challenges: \n",
        " \n",
        " 3.1 Identify the information (messages) are true or not. (Reliability problem)\n",
        "When we receive the information, we will face a problem, that is, how do we determine the authenticity and credibility of the information. In my opinion, a lot of false information will be posted on the social media, to achieve some people's goals (profit or something else). Social media such as Facebook and Twitter do not have the tools to detect rumours posted on the platform. They need such tools, so it can remove rumours as quickly as possible to avoid problems. Most social media rely on their employees and time to filter rumours, but the number of social media users exceeds our imagination, which is a big challenge for manually checking the accuracy of all the information on social media (Vohra and Kakkar, 2018). \n",
        "\n",
        "Vohra and Kakkar (2018) also gives an example, June 2016, \"Facebook Exclusive Notice\" is spread on social media, and information requires users to copy specific texts to Facebook, which will help them retain the exclusive rights to their personal data. In the end, this proved to be a rumour, but thousands of Facebook users shared the news and became victims of rumour.\n",
        "\n",
        "3.2 How to classify all the information they collect to get the useful information\n",
        "After we identify which are the rumours information or massages. We can delete them, and start to consider how to classify the information. Just like what I said before, is a big challenge to manually checking all the information on social media. Manually classifying information is also a big challenge. Information classification refers to the evaluation of value for information. At least the following must be determined before evaluating the value of the data/information: Data types, users accessing the data and keywords.\n",
        "\n",
        "3.3 How to let users receive this information\n",
        "Some of the user may turns off the notification, they will not receive the information or messages. On the other hand, the user may not interest in the messages or information, so they just ignore it. \n",
        "\n",
        "4. Algorithm & Solutions: \n",
        "Traditional rumor detection models rely more on manual design features. These features focus on textual content and user information. For instance, design different types of functions (sentence length, number of emotional words, age of users, number of followers) to assess the credibility of messages on specific topics (Castillo et al., 2011). Liu et al. (2015) proposed a verification function by considering the contradictory beliefs of the crowd as a debate on authenticity. In the same year, Wu et al. (2015) published a high-order propagation model that could improve the idea of rumor detection.\n",
        "However, these feature-based approaches are likely to be biased, easily restricted, and require a lot of time. They are usually designed for a specific situation or application, that means they might have a uniqueness. So, there is no guarantee that they will be used perfectly in other applications or situations.\n",
        "\n",
        "In order to address the issues of traditional methods, researchers can use deep neural networks to learn efficient features automatically for rumour detection. For example, CNN and RNN.\n",
        "As mentioned by Yu et al. (2017), the use of convolutional neural networks (CNN) in repost sequences can be used to capture the interactions among high-level features. Also, CNN is already applied in text semantic analysis (Kalchbrenner et al., 2014). RNN is use for sequence modelling in natural languages processing tasks like classify the text and machine translation. \n",
        "\n",
        "CNN:\n",
        "First we need to derive the feature vector of each departed repost fi = {w1, . . . , wk} of converted repost sequence F = {fi}. We first use word embeddings vector wi ∈ Rd to represent each word wi, d is dimension of word embeddings. Then each departed repost fi of length n (padded when necessary) is represented as instance matrix:\n",
        "W1:n = w1 ⊕ w2 ⊕ · · · wn (⊕ is the concatenation operator, so w1:n ∈ R d×n).\n",
        "\n",
        "Then the convolution operations are performed to obtain a convolutional layer: G ∈ R d × h (h is the length of words window applied to produce a new feature). Applying a nonlinear function to this result yields the elements of the feature map: ci = ReLU(< G, wi:i+h−1 >F + b). Then we max-pooling the feature map to obtain the maximum value cˆ = max(c) for the correlation to the weight matrix G.\n",
        "\n",
        "Finally, assuming that length of the feature vector is L, we can get the variable length matrix formula, F = {xi} ∈ R E×|F |, and finally we input the resulting F into the RNN algorithm.\n",
        "\n",
        "RNN:\n",
        "RNN uses the recurrent unit to process the variable length sequence. The update recurrent unit is based on the previously hidden state hi−1 and current input xi. Here is the method for calculating the hidden state hi:\n",
        "\n",
        "After loading F into RNN，we can get all the hidden state of each interval and take the final hidden state h|F|. The objective function of rumor detection is the log-likelihood of predicting the label y ∈ {0, 1}: O(|F|) = log p(y|h|F|), p(1|hi) = σ(hi · s) and p(0|hi) = 1 − p(1|hi). where s is weight vector and will be learnt during training.\n",
        "\n",
        "We can introduce a parameter β ∈ [0, 1], which is a reliable point. This parameter is obtained by first reaching the prediction threshold: β = nf /|F|. The goal of our first part is to maximize the probability of prediction after this point in time：. The goal of the second part is to minimize β: . We also need to guarantee the reliability of the detection point. This means that we want to ensure that the prediction probabilities after this detection point should be stable and scale out the threshold:. Finally, we introduce two hyper-parameters λ0 and λ1 to combine these three goals:.\n",
        "Finally, we just determine the value of β, if β closer to 1 means the reliability of this message (information) is higher. On the contrary, the reliability is getting lower and lower.\n",
        "\n",
        "In my opinion, the most difficult part of solve the challenges mentioned before is how to let user receive the information and change their mind to support another option. For the first challenge, we can solve it by design a particular algorithm or improve the algorithm now we have. Combine with manual design features also is a great idea, that means we can focus on the function we need. We can Train the model multiple times to increase the success rate.\n",
        "For challenge two, we also can use machine learning algorithm to set up a model and then classify the information and get the useful information. Create more classifiers, more precise keywords can help solve classification problems. In this part, I strongly recommend using manual design features, because they can design different function for different object, and evaluate the specific topic massages.\n",
        "For the final challenge, unfortunately, we can only let users see information by sending messages or using ads on some websites, software, and platforms. \n",
        "\n",
        "5. Ethical issues and Social consequence: \n",
        "For this topic, I think ethical issues are not a common problem. Unless user turn off the notification remain option, we still can send the message to them. Then that’s a ethical issue, we disturb the user. The other issue is privacy problem. When we detecting the message true or not, we may need user’s information or previous post or message. If someone trying to sold the user’s information, then this will be a ethical issue. Standing from the perspective of society, change user’s minds to support other one is a little bit unfair I think.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. Reference list:\n",
        "Castillo, C., Mendoza, M., & Poblete, B. 2011, “Information credibility on twitter,” in Proceedings of WWW, pp. 675–684.\n",
        "\n",
        "Kalchbrenner, N., Grefenstette, E., & Blunsom, E., 2014, “A convolutional neural network for modelling sentences,” arXiv preprint arXiv:1404.2188.\n",
        "\n",
        "Liu, X., Nourbakhsh, A., Li, Q., Fang, R., & S. Shah, 2015, “Real-time rumor debunking on twitter,” in Proceedings of CIKM, pp. 1867–1870.\n",
        "\n",
        "Wu, K., Yang, S., & Zhu, K. G, 2015, “False rumors detection on sina weibo by propagation structures,” in Proceedings of ICDE. IEEE, pp. 651–662.\n",
        "\n",
        "Vohra, M. & Kakkar, M. (2018). Detection of Rumor in Social Media. 8th International Conference on Cloud Computing, Data Science & Engineering.\n",
        "\n",
        "Yu, F., Liu, Q., Wu, S., Wang, L., & Tan, T., 2017, “A convolutional approach for misinformation identification,” in Proceedings of IJCAI.\n"
      ]
    }
  ]
}